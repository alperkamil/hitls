{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classification of Map-Cam Pairs\n",
    "In this notebook, we train an SVM to check whether one satellite image contains the other. We use the extracted features of the images using the pre-trained [MobileNet](https://keras.io/applications/#mobilenet) implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of 0s and 1s :\n",
      "0\t 0.5\n",
      "1\t 0.5\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "from config import CSV_PATH, FEATURE_PATH\n",
    "\n",
    "with open(FEATURE_PATH,'br') as f:\n",
    "    feature_dict = pickle.load(f)\n",
    "img_idx, preds = feature_dict['img_idx'], feature_dict['preds']\n",
    "\n",
    "y = []\n",
    "X = []\n",
    "\n",
    "csv_paths = glob.glob(CSV_PATH+'*.csv')\n",
    "for path in csv_paths:\n",
    "    with open(path,'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if len(row) == 4:\n",
    "                y.append(int(row[3]))\n",
    "                x = np.concatenate((preds[img_idx[row[1]]],preds[img_idx[row[2]]]))\n",
    "                X.append(x)\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "print('Distribution of 0s and 1s :')\n",
    "print('0\\t',1-np.sum(y)/y.shape[0])\n",
    "print('1\\t',np.sum(y)/y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use one fifth of the dataset as the test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123457)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an SVM using Cross-Validated Grid-Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 0.002, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.589 (+/-0.053) for {'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.873 (+/-0.031) for {'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.882 (+/-0.029) for {'gamma': 0.002, 'kernel': 'rbf'}\n",
      "0.881 (+/-0.034) for {'gamma': 0.003, 'kernel': 'rbf'}\n",
      "0.783 (+/-0.034) for {'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.88       297\n",
      "           1       0.84      0.97      0.90       303\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       600\n",
      "   macro avg       0.90      0.89      0.89       600\n",
      "weighted avg       0.90      0.89      0.89       600\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 0.003, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.585 (+/-0.050) for {'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.855 (+/-0.037) for {'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.870 (+/-0.036) for {'gamma': 0.002, 'kernel': 'rbf'}\n",
      "0.874 (+/-0.040) for {'gamma': 0.003, 'kernel': 'rbf'}\n",
      "0.712 (+/-0.050) for {'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89       297\n",
      "           1       0.86      0.96      0.91       303\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       600\n",
      "   macro avg       0.91      0.90      0.90       600\n",
      "weighted avg       0.91      0.90      0.90       600\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [2e-3] }]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5, scoring='%s_macro' % score, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Human Recognition\n",
    "In this case, we train an SVM to capture human capabilities for checking if an image contains another image or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of 0s and 1s :\n",
      "0\t 0.13\n",
      "1\t 0.87\n"
     ]
    }
   ],
   "source": [
    "from config import TABLE_PATH\n",
    "\n",
    "y_ = []\n",
    "X_ = []\n",
    "with open(TABLE_PATH,'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader, None)\n",
    "    for row in reader:\n",
    "        y_.append(int(row[9]))\n",
    "        x = np.concatenate((preds[img_idx[row[5]]],preds[img_idx[row[6]]]))\n",
    "        X_.append(x)\n",
    "np.sum(y_train)/y_train.shape[0]\n",
    "y_ = np.array(y_)\n",
    "X_ = np.array(X_)\n",
    "\n",
    "print('Distribution of 0s and 1s :')\n",
    "print('0\\t',1-np.sum(y_)/y_.shape[0])\n",
    "print('1\\t',np.sum(y_)/y_.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one fifth of the dataset as the test set \n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, y_, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an SVM using Cross-Validated Grid-Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 0.002, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.957 (+/-0.016) for {'gamma': 0.002, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.50      0.64        16\n",
      "           1       0.91      0.99      0.95        84\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       100\n",
      "   macro avg       0.90      0.74      0.79       100\n",
      "weighted avg       0.91      0.91      0.90       100\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 0.002, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.663 (+/-0.132) for {'gamma': 0.002, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.50      0.64        16\n",
      "           1       0.91      0.99      0.95        84\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       100\n",
      "   macro avg       0.90      0.74      0.79       100\n",
      "weighted avg       0.91      0.91      0.90       100\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [2e-3] }]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5, scoring='%s_macro' % score, n_jobs=-1)\n",
    "    clf.fit(X_train_, y_train_)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test_, clf.predict(X_test_)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
