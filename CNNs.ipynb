{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classification with Features Extracted by CNNs\n",
    "In this notebook, we train an SVM to check whether one satellite image contains the other. We use the extracted features of the images using the pre-trained [MobileNet](https://keras.io/applications/#mobilenet) implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 3000\n",
      "\n",
      "Distribution of 0s and 1s:\n",
      "0\t 0.5\n",
      "1\t 0.5\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "from config import CSV_PATH, FEATURE_PATH\n",
    "\n",
    "with open(FEATURE_PATH,'br') as f:\n",
    "    feature_dict = pickle.load(f)\n",
    "img_idx, preds = feature_dict['img_idx'], feature_dict['preds']\n",
    "\n",
    "y = []\n",
    "X = []\n",
    "\n",
    "csv_paths = glob.glob(CSV_PATH+'*.csv')\n",
    "for path in csv_paths:\n",
    "    with open(path,'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if len(row) == 4:\n",
    "                y.append(int(row[3]))\n",
    "                x = np.concatenate((preds[img_idx[row[1]]],preds[img_idx[row[2]]]))\n",
    "                X.append(x)\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "print('Number of samples:',X.shape[0])\n",
    "print()\n",
    "\n",
    "print('Distribution of 0s and 1s:')\n",
    "print('0\\t',1-np.sum(y)/y.shape[0])\n",
    "print('1\\t',np.sum(y)/y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use one fifth of the dataset as the test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123457)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an SVM using Cross-Validated Grid-Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 0.002, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.882 (+/-0.029) for {'gamma': 0.002, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.88       297\n",
      "           1       0.84      0.97      0.90       303\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       600\n",
      "   macro avg       0.90      0.89      0.89       600\n",
      "weighted avg       0.90      0.89      0.89       600\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 0.002, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.870 (+/-0.036) for {'gamma': 0.002, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.88       297\n",
      "           1       0.84      0.97      0.90       303\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       600\n",
      "   macro avg       0.90      0.89      0.89       600\n",
      "weighted avg       0.90      0.89      0.89       600\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 0.002, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.869 (+/-0.037) for {'gamma': 0.002, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.88       297\n",
      "           1       0.84      0.97      0.90       303\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       600\n",
      "   macro avg       0.90      0.89      0.89       600\n",
      "weighted avg       0.90      0.89      0.89       600\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [2e-3] }]\n",
    "\n",
    "scores = ['precision', 'recall', 'f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5, scoring='%s_macro' % score, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "clf_ = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Human Capability of Matching\n",
    "In this case, we train an SVM to capture human capabilities for checking if an image contains another image or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1200\n",
      "\n",
      "Distribution of 0s and 1s :\n",
      "0\t 0.37\n",
      "1\t 0.63\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "V = 'C'\n",
    "\n",
    "if V == 'A':\n",
    "    from config import TRAIN_PATH as TRAIN_PATH\n",
    "    from config import TEST_PATH as TEST_PATH\n",
    "    b,s,t = 9,5,6\n",
    "elif V == 'B':\n",
    "    from config import TRAINB_PATH as TRAIN_PATH\n",
    "    from config import TESTB_PATH as TEST_PATH\n",
    "    b,s,t = 62,5,6\n",
    "elif V == 'C':\n",
    "    from config import TRAINC_PATH as TRAIN_PATH\n",
    "    from config import TESTC_PATH as TEST_PATH\n",
    "    b,s,t = 62,5,6\n",
    "\n",
    "def load_from_csv(path):\n",
    "    y = []\n",
    "    X = []\n",
    "    with open(path,'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader, None)\n",
    "        for row in reader:\n",
    "            y.append(int(row[b]))\n",
    "            x = np.concatenate((preds[img_idx[row[s]]],preds[img_idx[row[t]]]))\n",
    "            X.append(x)\n",
    "            \n",
    "    y = np.array(y)\n",
    "    X = np.array(X)\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "X_train_, y_train_ = load_from_csv(TRAIN_PATH)\n",
    "X_test_, y_test_ = load_from_csv(TEST_PATH)\n",
    "\n",
    "print('Number of training samples:',X_train_.shape[0])\n",
    "print()\n",
    "\n",
    "print('Distribution of 0s and 1s :')\n",
    "print('0\\t',1-np.sum(y_train_)/y_train_.shape[0])\n",
    "print('1\\t',np.sum(y_train_)/y_train_.shape[0])\n",
    "\n",
    "### Split the dataset into training and test sets\n",
    "# Use one fifth of the dataset as the test set \n",
    "# X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, y_, test_size=0.2)\n",
    "\n",
    "# from utils import get_pcomp\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train_ = scaler.fit_transform(X_train_)\n",
    "# X_test_ = scaler.transform(X_test_)\n",
    "\n",
    "# pcomp = get_pcomp(X_train_)  # Threshold is t=0.99999 (1-eps)\n",
    "# print('Number of PCA components: ',pcomp)\n",
    "# pca = PCA(n_components=pcomp)\n",
    "# X_train_ = pca.fit_transform(X_train_)\n",
    "# X_test_ = pca.transform(X_test_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an SVM using Cross-Validated Grid-Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alper\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.617 (+/-0.391) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.655 (+/-0.143) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.597 (+/-0.307) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.315 (+/-0.001) for {'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.616 (+/-0.332) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.573 (+/-0.058) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.616 (+/-0.126) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.593 (+/-0.307) for {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.616 (+/-0.332) for {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.578 (+/-0.054) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.553 (+/-0.055) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.605 (+/-0.112) for {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.616 (+/-0.332) for {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.578 (+/-0.054) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.546 (+/-0.050) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.554 (+/-0.054) for {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.616 (+/-0.332) for {'C': 10000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.578 (+/-0.054) for {'C': 10000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.548 (+/-0.049) for {'C': 10000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.543 (+/-0.024) for {'C': 10000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.20      0.30       109\n",
      "           1       0.67      0.91      0.77       191\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       300\n",
      "   macro avg       0.62      0.56      0.53       300\n",
      "weighted avg       0.63      0.65      0.60       300\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.507 (+/-0.017) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.569 (+/-0.062) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.529 (+/-0.034) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.514 (+/-0.020) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.566 (+/-0.055) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.571 (+/-0.079) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.529 (+/-0.033) for {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.514 (+/-0.020) for {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.570 (+/-0.051) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.551 (+/-0.055) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.564 (+/-0.071) for {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.514 (+/-0.020) for {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.570 (+/-0.051) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.546 (+/-0.050) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.553 (+/-0.053) for {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.514 (+/-0.020) for {'C': 10000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.570 (+/-0.051) for {'C': 10000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.547 (+/-0.049) for {'C': 10000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.543 (+/-0.026) for {'C': 10000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.24      0.33       109\n",
      "           1       0.67      0.87      0.76       191\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       300\n",
      "   macro avg       0.59      0.56      0.54       300\n",
      "weighted avg       0.61      0.64      0.60       300\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.405 (+/-0.032) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.545 (+/-0.079) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.458 (+/-0.076) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.387 (+/-0.001) for {'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.420 (+/-0.043) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.566 (+/-0.057) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.558 (+/-0.095) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.461 (+/-0.077) for {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.420 (+/-0.043) for {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.570 (+/-0.054) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.551 (+/-0.056) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.551 (+/-0.084) for {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.420 (+/-0.043) for {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.570 (+/-0.054) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.546 (+/-0.050) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.553 (+/-0.054) for {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.420 (+/-0.043) for {'C': 10000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.570 (+/-0.054) for {'C': 10000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.547 (+/-0.049) for {'C': 10000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.543 (+/-0.024) for {'C': 10000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.39      0.42       109\n",
      "           1       0.68      0.73      0.70       191\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       300\n",
      "   macro avg       0.56      0.56      0.56       300\n",
      "weighted avg       0.59      0.61      0.60       300\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "                     'C': [1, 10, 100, 1000, 10000]}]\n",
    "\n",
    "scores = ['precision', 'recall', 'f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5, scoring='%s_macro' % score, n_jobs=-1)\n",
    "    clf.fit(X_train_, y_train_)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test_, clf.predict(X_test_)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'hidden_layer_sizes': (64, 64)}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.556 (+/-0.051) for {'hidden_layer_sizes': (64, 64)}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.41      0.42       109\n",
      "           1       0.67      0.69      0.68       191\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       300\n",
      "   macro avg       0.55      0.55      0.55       300\n",
      "weighted avg       0.58      0.59      0.58       300\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tuned_parameters = [{'hidden_layer_sizes' : [(64,64)]}]\n",
    "\n",
    "# (i*10+50,) for i in range(1,5)]\n",
    "    \n",
    "scores = ['f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(MLPClassifier(), tuned_parameters, cv=5, scoring='%s_macro' % score, n_jobs=-1)\n",
    "    clf.fit(X_train_, y_train_)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test_, clf.predict(X_test_)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
