{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1200\n",
      "\n",
      "Distribution of 0s and 1s :\n",
      "0\t 0.5391666666666667\n",
      "1\t 0.4608333333333333\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "V = 'B'\n",
    "\n",
    "if V == 'A':\n",
    "    from config import TRAIN_PATH as TRAIN_PATH\n",
    "    from config import TEST_PATH as TEST_PATH\n",
    "    b,s,t = 9,10,61\n",
    "elif V == 'B':\n",
    "    from config import TRAINB_PATH as TRAIN_PATH\n",
    "    from config import TESTB_PATH as TEST_PATH\n",
    "    b,s,t = 62,10,61\n",
    "elif V == 'C':\n",
    "    from config import TRAINC_PATH as TRAIN_PATH\n",
    "    from config import TESTC_PATH as TEST_PATH\n",
    "    b,s,t = 62,10,61\n",
    "\n",
    "def load_from_csv(path):\n",
    "    y = []\n",
    "    X = []\n",
    "    with open(path,'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader, None)\n",
    "        for row in reader:\n",
    "            y.append(int(row[b]))\n",
    "            X.append([int(e) for e in row[s:t]])\n",
    "            \n",
    "    y = np.array(y)\n",
    "    X = np.array(X)\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "X_train, y_train = load_from_csv(TRAIN_PATH)\n",
    "X_test, y_test = load_from_csv(TEST_PATH)\n",
    "\n",
    "print('Number of training samples:',X_train.shape[0])\n",
    "print()\n",
    "\n",
    "print('Distribution of 0s and 1s :')\n",
    "print('0\\t',1-np.sum(y_train)/y_train.shape[0])\n",
    "print('1\\t',np.sum(y_train)/y_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General framework for grid search with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def grid_search_and_test(estimator, tuned_parameters):\n",
    "\n",
    "    scores = ['precision', 'recall', 'f1']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(estimator, tuned_parameters, cv=5, scoring='%s_macro' % score, n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "        \n",
    "#     return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 0.8}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.529 (+/-0.067) for {'alpha': 0.05}\n",
      "0.529 (+/-0.066) for {'alpha': 0.1}\n",
      "0.529 (+/-0.066) for {'alpha': 0.15000000000000002}\n",
      "0.529 (+/-0.066) for {'alpha': 0.2}\n",
      "0.529 (+/-0.066) for {'alpha': 0.25}\n",
      "0.529 (+/-0.066) for {'alpha': 0.3}\n",
      "0.529 (+/-0.066) for {'alpha': 0.35000000000000003}\n",
      "0.529 (+/-0.069) for {'alpha': 0.4}\n",
      "0.529 (+/-0.069) for {'alpha': 0.45}\n",
      "0.529 (+/-0.069) for {'alpha': 0.5}\n",
      "0.529 (+/-0.069) for {'alpha': 0.55}\n",
      "0.529 (+/-0.069) for {'alpha': 0.6000000000000001}\n",
      "0.529 (+/-0.069) for {'alpha': 0.6500000000000001}\n",
      "0.529 (+/-0.069) for {'alpha': 0.7000000000000001}\n",
      "0.529 (+/-0.069) for {'alpha': 0.7500000000000001}\n",
      "0.530 (+/-0.067) for {'alpha': 0.8}\n",
      "0.530 (+/-0.067) for {'alpha': 0.8500000000000001}\n",
      "0.530 (+/-0.067) for {'alpha': 0.9000000000000001}\n",
      "0.530 (+/-0.067) for {'alpha': 0.9500000000000001}\n",
      "0.530 (+/-0.067) for {'alpha': 1.0}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.64      0.60       156\n",
      "           1       0.55      0.47      0.51       144\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       300\n",
      "   macro avg       0.56      0.56      0.55       300\n",
      "weighted avg       0.56      0.56      0.56       300\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 0.8}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.529 (+/-0.065) for {'alpha': 0.05}\n",
      "0.528 (+/-0.065) for {'alpha': 0.1}\n",
      "0.528 (+/-0.065) for {'alpha': 0.15000000000000002}\n",
      "0.528 (+/-0.065) for {'alpha': 0.2}\n",
      "0.528 (+/-0.065) for {'alpha': 0.25}\n",
      "0.528 (+/-0.065) for {'alpha': 0.3}\n",
      "0.528 (+/-0.065) for {'alpha': 0.35000000000000003}\n",
      "0.529 (+/-0.067) for {'alpha': 0.4}\n",
      "0.529 (+/-0.067) for {'alpha': 0.45}\n",
      "0.529 (+/-0.067) for {'alpha': 0.5}\n",
      "0.529 (+/-0.067) for {'alpha': 0.55}\n",
      "0.529 (+/-0.067) for {'alpha': 0.6000000000000001}\n",
      "0.529 (+/-0.067) for {'alpha': 0.6500000000000001}\n",
      "0.529 (+/-0.067) for {'alpha': 0.7000000000000001}\n",
      "0.529 (+/-0.067) for {'alpha': 0.7500000000000001}\n",
      "0.530 (+/-0.066) for {'alpha': 0.8}\n",
      "0.530 (+/-0.066) for {'alpha': 0.8500000000000001}\n",
      "0.530 (+/-0.066) for {'alpha': 0.9000000000000001}\n",
      "0.530 (+/-0.066) for {'alpha': 0.9500000000000001}\n",
      "0.530 (+/-0.066) for {'alpha': 1.0}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.64      0.60       156\n",
      "           1       0.55      0.47      0.51       144\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       300\n",
      "   macro avg       0.56      0.56      0.55       300\n",
      "weighted avg       0.56      0.56      0.56       300\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 0.8}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.529 (+/-0.065) for {'alpha': 0.05}\n",
      "0.528 (+/-0.065) for {'alpha': 0.1}\n",
      "0.528 (+/-0.065) for {'alpha': 0.15000000000000002}\n",
      "0.528 (+/-0.065) for {'alpha': 0.2}\n",
      "0.528 (+/-0.065) for {'alpha': 0.25}\n",
      "0.528 (+/-0.065) for {'alpha': 0.3}\n",
      "0.528 (+/-0.065) for {'alpha': 0.35000000000000003}\n",
      "0.529 (+/-0.067) for {'alpha': 0.4}\n",
      "0.529 (+/-0.067) for {'alpha': 0.45}\n",
      "0.529 (+/-0.067) for {'alpha': 0.5}\n",
      "0.529 (+/-0.067) for {'alpha': 0.55}\n",
      "0.529 (+/-0.067) for {'alpha': 0.6000000000000001}\n",
      "0.529 (+/-0.067) for {'alpha': 0.6500000000000001}\n",
      "0.529 (+/-0.067) for {'alpha': 0.7000000000000001}\n",
      "0.529 (+/-0.067) for {'alpha': 0.7500000000000001}\n",
      "0.529 (+/-0.065) for {'alpha': 0.8}\n",
      "0.529 (+/-0.065) for {'alpha': 0.8500000000000001}\n",
      "0.529 (+/-0.065) for {'alpha': 0.9000000000000001}\n",
      "0.529 (+/-0.065) for {'alpha': 0.9500000000000001}\n",
      "0.529 (+/-0.065) for {'alpha': 1.0}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.64      0.60       156\n",
      "           1       0.55      0.47      0.51       144\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       300\n",
      "   macro avg       0.56      0.56      0.55       300\n",
      "weighted avg       0.56      0.56      0.56       300\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "tuned_parameters = [{'alpha': np.arange(0.05,1.05,0.05)}]\n",
    "grid_search_and_test(BernoulliNB(), tuned_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.518 (+/-0.110) for {'penalty': None}\n",
      "0.464 (+/-0.139) for {'penalty': 'l2'}\n",
      "0.521 (+/-0.060) for {'penalty': 'l1'}\n",
      "0.464 (+/-0.139) for {'penalty': 'elasticnet'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.35      0.41       156\n",
      "           1       0.46      0.60      0.52       144\n",
      "\n",
      "   micro avg       0.47      0.47      0.47       300\n",
      "   macro avg       0.48      0.48      0.47       300\n",
      "weighted avg       0.48      0.47      0.46       300\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.502 (+/-0.053) for {'penalty': None}\n",
      "0.497 (+/-0.038) for {'penalty': 'l2'}\n",
      "0.511 (+/-0.042) for {'penalty': 'l1'}\n",
      "0.497 (+/-0.038) for {'penalty': 'elasticnet'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.35      0.41       156\n",
      "           1       0.46      0.60      0.52       144\n",
      "\n",
      "   micro avg       0.47      0.47      0.47       300\n",
      "   macro avg       0.48      0.48      0.47       300\n",
      "weighted avg       0.48      0.47      0.46       300\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.480 (+/-0.024) for {'penalty': None}\n",
      "0.437 (+/-0.126) for {'penalty': 'l2'}\n",
      "0.455 (+/-0.103) for {'penalty': 'l1'}\n",
      "0.437 (+/-0.126) for {'penalty': 'elasticnet'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.46      0.48       156\n",
      "           1       0.45      0.48      0.46       144\n",
      "\n",
      "   micro avg       0.47      0.47      0.47       300\n",
      "   macro avg       0.47      0.47      0.47       300\n",
      "weighted avg       0.47      0.47      0.47       300\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\alper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\alper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "tuned_parameters = [{'penalty': [None, 'l2', 'l1', 'elasticnet']}]\n",
    "grid_search_and_test(Perceptron(), tuned_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l2'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.539 (+/-0.059) for {'penalty': 'l2'}\n",
      "0.538 (+/-0.060) for {'penalty': 'l1'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.68      0.59       156\n",
      "           1       0.49      0.33      0.40       144\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       300\n",
      "   macro avg       0.51      0.51      0.49       300\n",
      "weighted avg       0.51      0.51      0.50       300\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l2'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.536 (+/-0.052) for {'penalty': 'l2'}\n",
      "0.535 (+/-0.055) for {'penalty': 'l1'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.68      0.59       156\n",
      "           1       0.49      0.33      0.40       144\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       300\n",
      "   macro avg       0.51      0.51      0.49       300\n",
      "weighted avg       0.51      0.51      0.50       300\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l2'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.532 (+/-0.051) for {'penalty': 'l2'}\n",
      "0.531 (+/-0.056) for {'penalty': 'l1'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.68      0.59       156\n",
      "           1       0.49      0.33      0.40       144\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       300\n",
      "   macro avg       0.51      0.51      0.49       300\n",
      "weighted avg       0.51      0.51      0.50       300\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\alper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "tuned_parameters = [{'penalty': ['l2', 'l1']}]\n",
    "grid_search_and_test(LogisticRegression(), tuned_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.565 (+/-0.096) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.270 (+/-0.001) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.270 (+/-0.001) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.270 (+/-0.001) for {'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.550 (+/-0.066) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.557 (+/-0.098) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.270 (+/-0.001) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.270 (+/-0.001) for {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.553 (+/-0.058) for {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.551 (+/-0.069) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.560 (+/-0.099) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.270 (+/-0.001) for {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.538 (+/-0.052) for {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.550 (+/-0.028) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.554 (+/-0.069) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.560 (+/-0.099) for {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.544 (+/-0.069) for {'C': 10000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.558 (+/-0.062) for {'C': 10000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.539 (+/-0.049) for {'C': 10000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.555 (+/-0.064) for {'C': 10000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.544 (+/-0.069) for {'C': 100000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.545 (+/-0.060) for {'C': 100000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.550 (+/-0.028) for {'C': 100000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.547 (+/-0.056) for {'C': 100000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.86      0.65       156\n",
      "           1       0.51      0.16      0.24       144\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       300\n",
      "   macro avg       0.52      0.51      0.45       300\n",
      "weighted avg       0.52      0.52      0.46       300\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.537 (+/-0.040) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.545 (+/-0.061) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.533 (+/-0.043) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.552 (+/-0.056) for {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.545 (+/-0.061) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.536 (+/-0.043) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.538 (+/-0.052) for {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.547 (+/-0.028) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.548 (+/-0.060) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.536 (+/-0.043) for {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.544 (+/-0.069) for {'C': 10000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.557 (+/-0.059) for {'C': 10000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.535 (+/-0.043) for {'C': 10000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.549 (+/-0.055) for {'C': 10000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.544 (+/-0.069) for {'C': 100000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.545 (+/-0.060) for {'C': 100000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.548 (+/-0.028) for {'C': 100000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.542 (+/-0.050) for {'C': 100000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.54      0.53       156\n",
      "           1       0.47      0.45      0.46       144\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       300\n",
      "   macro avg       0.49      0.49      0.49       300\n",
      "weighted avg       0.50      0.50      0.50       300\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.504 (+/-0.028) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.350 (+/-0.001) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.350 (+/-0.001) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.350 (+/-0.001) for {'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.539 (+/-0.066) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.504 (+/-0.026) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.350 (+/-0.001) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.350 (+/-0.001) for {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.551 (+/-0.057) for {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.537 (+/-0.061) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.508 (+/-0.026) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.350 (+/-0.001) for {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.538 (+/-0.052) for {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.544 (+/-0.032) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.541 (+/-0.060) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.508 (+/-0.026) for {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.543 (+/-0.068) for {'C': 10000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.557 (+/-0.060) for {'C': 10000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.530 (+/-0.039) for {'C': 10000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.542 (+/-0.056) for {'C': 10000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.543 (+/-0.068) for {'C': 100000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.544 (+/-0.059) for {'C': 100000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.545 (+/-0.033) for {'C': 100000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.537 (+/-0.049) for {'C': 100000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.54      0.53       156\n",
      "           1       0.47      0.45      0.46       144\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       300\n",
      "   macro avg       0.49      0.49      0.49       300\n",
      "weighted avg       0.50      0.50      0.50       300\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "                     'C': [1, 10, 100, 1000, 10000, 100000]}]\n",
    "grid_search_and_test(SVC(), tuned_parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
